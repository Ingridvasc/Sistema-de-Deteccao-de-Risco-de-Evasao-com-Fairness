# -*- coding: utf-8 -*-
"""analise_evasao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WCItvbbt_TsXnY3hpzO3ZAknfbLEA6l7
"""

# analise_evasao.py
"""
Sistema de Detecção de Risco de Evasão com Fairness
Análise de viés algorítmico em predição de evasão estudantil
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix,
    classification_report
)
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

# Configurações de visualização
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

print("=" * 80)
print("SISTEMA DE DETECÇÃO DE RISCO DE EVASÃO COM FAIRNESS")
print("=" * 80)

# ============================================================================
# 1. CARREGAMENTO E PRÉ-PROCESSAMENTO DOS DADOS
# ============================================================================

print("\n1. CARREGANDO E PREPARANDO OS DADOS...")

# Carregar dados
try:
    df = pd.read_csv('data.csv', sep=';')
    print(f"Dataset carregado: {df.shape[0]} registros, {df.shape[1]} variáveis")
except FileNotFoundError:
    print("ERRO: Arquivo 'data.csv' não encontrado.")
    print("Por favor, certifique-se de que o arquivo está no mesmo diretório.")
    exit()

# Exibir primeiras linhas
print("\nPrimeiras 5 linhas do dataset:")
print(df.head())

# Informações básicas
print("\nInformações do dataset:")
print(df.info())

# ============================================================================
# 2. ANÁLISE EXPLORATÓRIA DE DADOS (EDA)
# ============================================================================

print("\n" + "=" * 80)
print("2. ANÁLISE EXPLORATÓRIA DE DADOS")
print("=" * 80)

# Estatísticas descritivas
print("\nEstatísticas descritivas (variáveis numéricas):")
print(df.describe())

# Análise da variável target
print(f"\nDistribuição da variável Target:")
target_counts = df['Target'].value_counts()
print(target_counts)
print(f"\nProporções:")
print(target_counts / len(df) * 100)

# Converter target para binário (Dropout = 1, outros = 0)
df['Target_binary'] = df['Target'].apply(lambda x: 1 if x == 'Dropout' else 0)

# Análise de representação
print("\n" + "-" * 50)
print("ANÁLISE DE REPRESENTAÇÃO DEMOGRÁFICA")
print("-" * 50)

# Bolsistas
if 'Scholarship holder' in df.columns:
    scholarship_counts = df['Scholarship holder'].value_counts()
    print(f"\nBolsistas:")
    print(f"  Não bolsistas: {scholarship_counts.get(0, 0)} ({scholarship_counts.get(0, 0)/len(df)*100:.1f}%)")
    print(f"  Bolsistas: {scholarship_counts.get(1, 0)} ({scholarship_counts.get(1, 0)/len(df)*100:.1f}%)")

# Gênero
if 'Gender' in df.columns:
    gender_counts = df['Gender'].value_counts()
    print(f"\nGênero:")
    print(f"  Masculino: {gender_counts.get(1, 0)} ({gender_counts.get(1, 0)/len(df)*100:.1f}%)")
    print(f"  Feminino: {gender_counts.get(0, 0)} ({gender_counts.get(0, 0)/len(df)*100:.1f}%)")

# Idade
if 'Age at enrollment' in df.columns:
    print(f"\nIdade no ingresso:")
    print(f"  Média: {df['Age at enrollment'].mean():.1f} anos")
    print(f"  Mediana: {df['Age at enrollment'].median():.1f} anos")
    print(f"  Mínimo: {df['Age at enrollment'].min():.1f} anos")
    print(f"  Máximo: {df['Age at enrollment'].max():.1f} anos")

# Valores faltantes
print("\nValores faltantes por coluna:")
missing_values = df.isnull().sum()
missing_percent = (missing_values / len(df)) * 100
missing_df = pd.DataFrame({
    'Valores Faltantes': missing_values,
    'Percentual': missing_percent
})
print(missing_df[missing_df['Valores Faltantes'] > 0].sort_values('Percentual', ascending=False))

# ============================================================================
# 3. ANÁLISE DE CORRELAÇÕES E POSSÍVEIS VIÉSES
# ============================================================================

print("\n" + "-" * 50)
print("ANÁLISE DE CORRELAÇÕES")
print("-" * 50)

# Selecionar colunas numéricas para análise de correlação
numeric_cols = df.select_dtypes(include=[np.number]).columns

# Calcular correlações com o target
if len(numeric_cols) > 0:
    correlations = df[numeric_cols].corr()['Target_binary'].sort_values(ascending=False)
    print("\nTop 10 correlações com evasão (positivas):")
    print(correlations.head(10))

    print("\nTop 10 correlações com evasão (negativas):")
    print(correlations.tail(10))

# Análise de viés potencial
print("\n" + "-" * 50)
print("ANÁLISE DE VIÉS POTENCIAL")
print("-" * 50)

if 'Scholarship holder' in df.columns and 'Gender' in df.columns:
    # Taxa de evasão por grupo
    print("\nTaxa de evasão por grupo:")

    # Por bolsa
    for scholarship in [0, 1]:
        subset = df[df['Scholarship holder'] == scholarship]
        dropout_rate = subset['Target_binary'].mean() * 100
        label = "Não bolsista" if scholarship == 0 else "Bolsista"
        print(f"  {label}: {dropout_rate:.1f}%")

    # Por gênero
    for gender in [0, 1]:
        subset = df[df['Gender'] == gender]
        dropout_rate = subset['Target_binary'].mean() * 100
        label = "Feminino" if gender == 0 else "Masculino"
        print(f"  {label}: {dropout_rate:.1f}%")

# ============================================================================
# 4. PRÉ-PROCESSAMENTO PARA MODELAGEM
# ============================================================================

print("\n" + "=" * 80)
print("3. PREPARAÇÃO DOS DADOS PARA MODELAGEM")
print("=" * 80)

# Selecionar features para o modelo
# Vamos usar um conjunto básico de features baseadas na análise
features = [
    'Previous qualification (grade)',
    'Admission grade',
    'Age at enrollment',
    'Tuition fees up to date',
    'Scholarship holder',
    'Gender',
    'Curricular units 1st sem (grade)',
    'Curricular units 2nd sem (grade)',
    'Unemployment rate',
    'Inflation rate',
    'GDP'
]

# Verificar quais features estão disponíveis
available_features = [f for f in features if f in df.columns]
print(f"\nFeatures selecionadas ({len(available_features)}):")
for f in available_features:
    print(f"  - {f}")

# Preparar dados
X = df[available_features].copy()
y = df['Target_binary'].copy()

# Tratar valores faltantes
imputer = SimpleImputer(strategy='median')
X_imputed = imputer.fit_transform(X)
X = pd.DataFrame(X_imputed, columns=available_features)

# Split dos dados
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"\nDivisão dos dados:")
print(f"  Treino: {X_train.shape[0]} amostras ({len(X_train)/len(X)*100:.1f}%)")
print(f"  Validação: {X_val.shape[0]} amostras ({len(X_val)/len(X)*100:.1f}%)")
print(f"  Teste: {X_test.shape[0]} amostras ({len(X_test)/len(X)*100:.1f}%)")

# Normalização
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# ============================================================================
# 5. MODELO BASELINE
# ============================================================================

print("\n" + "=" * 80)
print("4. TREINANDO MODELO BASELINE")
print("=" * 80)

# Treinar modelo de regressão logística
model = LogisticRegression(
    max_iter=1000,
    random_state=42,
    class_weight='balanced'  # Para lidar com desbalanceamento
)

model.fit(X_train_scaled, y_train)

# Previsões
y_train_pred = model.predict(X_train_scaled)
y_val_pred = model.predict(X_val_scaled)
y_test_pred = model.predict(X_test_scaled)

# Probabilidades
y_test_proba = model.predict_proba(X_test_scaled)[:, 1]

# Métricas no conjunto de teste
print("\nMÉTRICAS DO MODELO NO CONJUNTO DE TESTE:")
print("-" * 40)

accuracy = accuracy_score(y_test, y_test_pred)
precision = precision_score(y_test, y_test_pred, zero_division=0)
recall = recall_score(y_test, y_test_pred, zero_division=0)
f1 = f1_score(y_test, y_test_pred, zero_division=0)
roc_auc = roc_auc_score(y_test, y_test_proba)

print(f"Acurácia: {accuracy:.4f}")
print(f"Precisão: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print(f"ROC-AUC: {roc_auc:.4f}")

# Matriz de confusão
cm = confusion_matrix(y_test, y_test_pred)
print("\nMatriz de Confusão:")
print(cm)

# ============================================================================
# 6. ANÁLISE DE FAIRNESS POR SUBGRUPOS - VERSÃO CORRIGIDA
# ============================================================================

print("\n" + "=" * 80)
print("5. ANÁLISE DE FAIRNESS POR SUBGRUPOS")
print("=" * 80)

# Preparar dados de teste com informações demográficas
# CORREÇÃO: Garantir a mesma ordem das features
test_indices = X_test.index

# Obter as features originais do dataset original
X_test_original = df.loc[test_indices, available_features].copy()

# Aplicar o mesmo pré-processamento (imputer e scaler) na ordem correta
X_test_imputed = pd.DataFrame(
    imputer.transform(X_test_original),
    columns=available_features,
    index=test_indices
)

X_test_scaled_df = pd.DataFrame(
    scaler.transform(X_test_imputed),
    columns=available_features,
    index=test_indices
)

# Adicionar informações demográficas
X_test_scaled_df['Scholarship holder'] = df.loc[test_indices, 'Scholarship holder'].values
X_test_scaled_df['Gender'] = df.loc[test_indices, 'Gender'].values

# Adicionar previsões e valores reais
X_test_scaled_df['y_true'] = y_test.values
X_test_scaled_df['y_pred'] = y_test_pred
X_test_scaled_df['y_proba'] = y_test_proba

print(f"\nDados preparados para análise de fairness: {X_test_scaled_df.shape[0]} amostras")
print(f"Features: {list(X_test_scaled_df.columns)}")

# Função para calcular métricas por grupo
def calculate_group_metrics(data, group_col, group_value, y_true_col='y_true', y_pred_col='y_pred'):
    group_data = data[data[group_col] == group_value]
    if len(group_data) == 0:
        return None

    y_true = group_data[y_true_col]
    y_pred = group_data[y_pred_col]

    # Calcular métricas básicas
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)

    # Calcular taxas específicas
    try:
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()

        # Taxas
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0

    except ValueError:
        # Caso haja apenas uma classe
        fpr = fnr = tpr = 0

    return {
        'n_samples': len(group_data),
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'fpr': fpr,
        'fnr': fnr,
        'tpr': tpr,
        'dropout_rate': y_true.mean()
    }

print("\n" + "-" * 50)
print("MÉTRICAS POR STATUS DE BOLSA")
print("-" * 50)

scholarship_metrics = {}
for scholarship in [0, 1]:
    metrics = calculate_group_metrics(X_test_scaled_df, 'Scholarship holder', scholarship)
    if metrics:
        scholarship_metrics[scholarship] = metrics
        label = "Não bolsista" if scholarship == 0 else "Bolsista"
        print(f"\n{label} (n={metrics['n_samples']}):")
        print(f"  Acurácia: {metrics['accuracy']:.4f}")
        print(f"  Precisão: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1']:.4f}")
        print(f"  FPR: {metrics['fpr']:.4f}")
        print(f"  FNR: {metrics['fnr']:.4f}")
        print(f"  Taxa de evasão real: {metrics['dropout_rate']:.4f}")

print("\n" + "-" * 50)
print("MÉTRICAS POR GÊNERO")
print("-" * 50)

gender_metrics = {}
for gender in [0, 1]:
    metrics = calculate_group_metrics(X_test_scaled_df, 'Gender', gender)
    if metrics:
        gender_metrics[gender] = metrics
        label = "Feminino" if gender == 0 else "Masculino"
        print(f"\n{label} (n={metrics['n_samples']}):")
        print(f"  Acurácia: {metrics['accuracy']:.4f}")
        print(f"  Precisão: {metrics['precision']:.4f}")
        print(f"  Recall: {metrics['recall']:.4f}")
        print(f"  F1-Score: {metrics['f1']:.4f}")
        print(f"  FPR: {metrics['fpr']:.4f}")
        print(f"  FNR: {metrics['fnr']:.4f}")
        print(f"  Taxa de evasão real: {metrics['dropout_rate']:.4f}")

# ============================================================================
# 7. ANÁLISE DE DISPARIDADE (FAIRNESS)
# ============================================================================

print("\n" + "-" * 50)
print("ANÁLISE DE DISPARIDADE (FAIRNESS METRICS)")
print("-" * 50)

# Calcular disparidades
def calculate_disparity(metric_dict, group1, group2, metric_name):
    if group1 in metric_dict and group2 in metric_dict:
        val1 = metric_dict[group1][metric_name]
        val2 = metric_dict[group2][metric_name]
        disparity = abs(val1 - val2)
        return disparity
    return None

# Coletar métricas por grupo (já coletadas acima)

# Calcular e exibir disparidades
print("\nDisparidades entre grupos:")

# Para bolsistas vs não bolsistas
if 0 in scholarship_metrics and 1 in scholarship_metrics:
    print("\nBolsistas vs Não bolsistas:")

    # Disparidade demográfica (diferença na taxa de predição positiva)
    pred_rate_0 = (X_test_scaled_df[X_test_scaled_df['Scholarship holder'] == 0]['y_pred'] == 1).mean()
    pred_rate_1 = (X_test_scaled_df[X_test_scaled_df['Scholarship holder'] == 1]['y_pred'] == 1).mean()
    demographic_disparity_original = abs(pred_rate_0 - pred_rate_1)
    print(f"  Disparidade demográfica: {demographic_disparity_original:.4f}")

    # Equalized Odds (diferença em FPR e FNR)
    fpr_disparity_original = calculate_disparity(scholarship_metrics, 0, 1, 'fpr') or 0
    fnr_disparity_original = calculate_disparity(scholarship_metrics, 0, 1, 'fnr') or 0
    print(f"  Disparidade FPR (Equalized Odds): {fpr_disparity_original:.4f}")
    print(f"  Disparidade FNR (Equalized Odds): {fnr_disparity_original:.4f}")

# Para gênero
if 0 in gender_metrics and 1 in gender_metrics:
    print("\nFeminino vs Masculino:")

    # Disparidade demográfica
    pred_rate_f = (X_test_scaled_df[X_test_scaled_df['Gender'] == 0]['y_pred'] == 1).mean()
    pred_rate_m = (X_test_scaled_df[X_test_scaled_df['Gender'] == 1]['y_pred'] == 1).mean()
    demographic_disparity_gender = abs(pred_rate_f - pred_rate_m)
    print(f"  Disparidade demográfica: {demographic_disparity_gender:.4f}")

    # Equalized Odds
    fpr_disparity_gender = calculate_disparity(gender_metrics, 0, 1, 'fpr')
    fnr_disparity_gender = calculate_disparity(gender_metrics, 0, 1, 'fnr')
    print(f"  Disparidade FPR (Equalized Odds): {fpr_disparity_gender:.4f}")
    print(f"  Disparidade FNR (Equalized Odds): {fnr_disparity_gender:.4f}")

# ============================================================================
# 8. MITIGAÇÃO DE VIÉS (THRESHOLD TUNING POR GRUPO)
# ============================================================================

print("\n" + "=" * 80)
print("6. MITIGAÇÃO DE VIÉS - THRESHOLD TUNING POR GRUPO")
print("=" * 80)

# Função para encontrar threshold ótimo por grupo
def find_optimal_threshold_by_group(data, group_col, group_value, target_col='y_true', proba_col='y_proba'):
    group_data = data[data[group_col] == group_value]
    if len(group_data) == 0:
        return 0.5

    y_true = group_data[target_col].values
    y_proba = group_data[proba_col].values

    # Testar diferentes thresholds
    best_f1 = 0
    best_threshold = 0.5

    for threshold in np.arange(0.3, 0.7, 0.01):
        y_pred = (y_proba >= threshold).astype(int)
        f1 = f1_score(y_true, y_pred, zero_division=0)

        if f1 > best_f1:
            best_f1 = f1
            best_threshold = threshold

    return best_threshold

# Encontrar thresholds ótimos por grupo
print("\nEncontrando thresholds ótimos por grupo:")

# Para bolsistas
threshold_scholarship_0 = find_optimal_threshold_by_group(X_test_scaled_df, 'Scholarship holder', 0)
threshold_scholarship_1 = find_optimal_threshold_by_group(X_test_scaled_df, 'Scholarship holder', 1)
print(f"  Não bolsistas: threshold ótimo = {threshold_scholarship_0:.3f}")
print(f"  Bolsistas: threshold ótimo = {threshold_scholarship_1:.3f}")

# Aplicar thresholds diferentes por grupo
print("\nAplicando thresholds ajustados por grupo...")

# Previsões com threshold ajustado
y_pred_fair = []
for idx, row in X_test_scaled_df.iterrows():
    proba = row['y_proba']
    if row['Scholarship holder'] == 0:
        threshold = threshold_scholarship_0
    else:
        threshold = threshold_scholarship_1

    y_pred_fair.append(1 if proba >= threshold else 0)

X_test_scaled_df['y_pred_fair'] = y_pred_fair

# Calcular métricas com o modelo ajustado
print("\nMÉTRICAS APÓS AJUSTE DE THRESHOLD POR GRUPO:")
print("-" * 40)

# Métricas gerais
accuracy_fair = accuracy_score(X_test_scaled_df['y_true'], X_test_scaled_df['y_pred_fair'])
precision_fair = precision_score(X_test_scaled_df['y_true'], X_test_scaled_df['y_pred_fair'], zero_division=0)
recall_fair = recall_score(X_test_scaled_df['y_true'], X_test_scaled_df['y_pred_fair'], zero_division=0)
f1_fair = f1_score(X_test_scaled_df['y_true'], X_test_scaled_df['y_pred_fair'], zero_division=0)

print(f"Acurácia: {accuracy_fair:.4f} (original: {accuracy:.4f})")
print(f"Precisão: {precision_fair:.4f} (original: {precision:.4f})")
print(f"Recall: {recall_fair:.4f} (original: {recall:.4f})")
print(f"F1-Score: {f1_fair:.4f} (original: {f1:.4f})")

# Análise de fairness após ajuste
print("\nANÁLISE DE FAIRNESS APÓS AJUSTE:")
print("-" * 40)

# Calcular métricas por grupo com o modelo ajustado
scholarship_metrics_fair = {}
for scholarship in [0, 1]:
    group_data = X_test_scaled_df[X_test_scaled_df['Scholarship holder'] == scholarship]
    if len(group_data) > 0:
        y_true = group_data['y_true']
        y_pred = group_data['y_pred_fair']

        try:
            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
            fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
        except ValueError:
            fpr = fnr = 0

        scholarship_metrics_fair[scholarship] = {
            'fpr': fpr,
            'fnr': fnr,
            'pred_rate': (y_pred == 1).mean()
        }

# Calcular disparidades após ajuste
if 0 in scholarship_metrics_fair and 1 in scholarship_metrics_fair:
    print("\nDisparidades após ajuste (Bolsistas vs Não bolsistas):")

    # Disparidade demográfica
    pred_rate_0_fair = scholarship_metrics_fair[0]['pred_rate']
    pred_rate_1_fair = scholarship_metrics_fair[1]['pred_rate']
    demographic_disparity_fair = abs(pred_rate_0_fair - pred_rate_1_fair)

    print(f"  Disparidade demográfica: {demographic_disparity_fair:.4f} (original: {demographic_disparity_original:.4f})")

    # Equalized Odds
    fpr_disparity_fair = abs(scholarship_metrics_fair[0]['fpr'] - scholarship_metrics_fair[1]['fpr'])
    fnr_disparity_fair = abs(scholarship_metrics_fair[0]['fnr'] - scholarship_metrics_fair[1]['fnr'])

    print(f"  Disparidade FPR: {fpr_disparity_fair:.4f} (original: {fpr_disparity_original:.4f})")
    print(f"  Disparidade FNR: {fnr_disparity_fair:.4f} (original: {fnr_disparity_original:.4f})")

# ============================================================================
# 9. VISUALIZAÇÕES
# ============================================================================

print("\n" + "=" * 80)
print("7. GERANDO VISUALIZAÇÕES")
print("=" * 80)

# Criar diretório para imagens se não existir
import os
if not os.path.exists('images'):
    os.makedirs('images')

# 1. Distribuição do Target
plt.figure(figsize=(10, 6))
target_dist = df['Target'].value_counts()
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
plt.bar(target_dist.index, target_dist.values, color=colors[:len(target_dist)])
plt.title('Distribuição do Target (Status do Aluno)', fontsize=16, fontweight='bold')
plt.xlabel('Status', fontsize=14)
plt.ylabel('Número de Alunos', fontsize=14)
plt.xticks(rotation=45)
plt.grid(axis='y', alpha=0.3)
for i, v in enumerate(target_dist.values):
    plt.text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')
plt.tight_layout()
plt.savefig('images/target_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# 2. Matriz de Confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Não Evasão', 'Evasão'],
            yticklabels=['Não Evasão', 'Evasão'])
plt.title('Matriz de Confusão - Modelo Baseline', fontsize=16, fontweight='bold')
plt.ylabel('Verdadeiro', fontsize=14)
plt.xlabel('Previsto', fontsize=14)
plt.tight_layout()
plt.savefig('images/confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# 3. Métricas por Grupo (Bolsistas)
if 0 in scholarship_metrics and 1 in scholarship_metrics:
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()

    metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1']
    metric_names = ['Acurácia', 'Precisão', 'Recall', 'F1-Score']

    for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):
        ax = axes[idx]
        values = [scholarship_metrics[0][metric], scholarship_metrics[1][metric]]
        groups = ['Não Bolsista', 'Bolsista']
        colors = ['#3498db', '#e74c3c']

        bars = ax.bar(groups, values, color=colors)
        ax.set_title(f'{name} por Status de Bolsa', fontsize=14, fontweight='bold')
        ax.set_ylabel(name, fontsize=12)
        ax.set_ylim(0, max(values) * 1.2)

        # Adicionar valores nas barras
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

        ax.grid(axis='y', alpha=0.3)

    plt.suptitle('Métricas do Modelo por Status de Bolsa', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig('images/metrics_by_scholarship.png', dpi=300, bbox_inches='tight')
    plt.show()

# 4. Comparação de Disparidades (Antes vs Depois)
if 0 in scholarship_metrics and 1 in scholarship_metrics:
    # Garantir que temos os valores
    fpr_disparity_original = calculate_disparity(scholarship_metrics, 0, 1, 'fpr') or 0
    fnr_disparity_original = calculate_disparity(scholarship_metrics, 0, 1, 'fnr') or 0

    disparities_data = {
        'Disparidade': ['Demográfica', 'FPR', 'FNR'],
        'Antes': [demographic_disparity_original, fpr_disparity_original, fnr_disparity_original],
        'Depois': [demographic_disparity_fair, fpr_disparity_fair, fnr_disparity_fair]
    }

    disparities_df = pd.DataFrame(disparities_data)

    plt.figure(figsize=(10, 6))
    x = np.arange(len(disparities_df))
    width = 0.35

    plt.bar(x - width/2, disparities_df['Antes'], width, label='Antes', color='#e74c3c', alpha=0.8)
    plt.bar(x + width/2, disparities_df['Depois'], width, label='Depois', color='#2ecc71', alpha=0.8)

    plt.xlabel('Métrica de Disparidade', fontsize=14)
    plt.ylabel('Valor da Disparidade', fontsize=14)
    plt.title('Comparação de Disparidades: Antes vs Depois do Ajuste', fontsize=16, fontweight='bold')
    plt.xticks(x, disparities_df['Disparidade'])
    plt.legend()
    plt.grid(axis='y', alpha=0.3)

    # Adicionar valores nas barras
    for i, (antes, depois) in enumerate(zip(disparities_df['Antes'], disparities_df['Depois'])):
        plt.text(i - width/2, antes + 0.005, f'{antes:.3f}', ha='center', va='bottom', fontweight='bold')
        plt.text(i + width/2, depois + 0.005, f'{depois:.3f}', ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.savefig('images/disparity_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

# ============================================================================
# 10. CONCLUSÕES E RECOMENDAÇÕES
# ============================================================================

print("\n" + "=" * 80)
print("8. CONCLUSÕES E RECOMENDAÇÕES")
print("=" * 80)

print("\nRESUMO DOS RESULTADOS:")
print("-" * 40)

print(f"""
1. DESEMPENHO DO MODELO:
   • Acurácia: {accuracy:.4f}
   • F1-Score: {f1:.4f}
   • ROC-AUC: {roc_auc:.4f}

2. ANÁLISE DE FAIRNESS (BOLSISTAS VS NÃO BOLSISTAS):
   • Taxa de evasão real: Bolsistas={scholarship_metrics[1]['dropout_rate']:.2%}, Não bolsistas={scholarship_metrics[0]['dropout_rate']:.2%}
   • Disparidade demográfica: {demographic_disparity_original:.4f}
   • Disparidade FPR (Equalized Odds): {fpr_disparity_original:.4f}
   • Disparidade FNR (Equalized Odds): {fnr_disparity_original:.4f}

3. APÓS MITIGAÇÃO DE VIÉS (Threshold Tuning):
   • Disparidade demográfica: {demographic_disparity_fair:.4f} (redução de {((demographic_disparity_original - demographic_disparity_fair)/demographic_disparity_original*100):.1f}%)
   • Disparidade FPR: {fpr_disparity_fair:.4f} (redução de {((fpr_disparity_original - fpr_disparity_fair)/fpr_disparity_original*100):.1f}%)
   • Trade-off: Acurácia reduzida em {abs(accuracy - accuracy_fair)*100:.1f}%

4. RECOMENDAÇÕES:
   a) Monitoramento contínuo das métricas de fairness
   b) Re-treinamento periódico com dados atualizados
   c) Implementação de thresholds dinâmicos por grupo
   d) Validação externa do modelo em outras instituições
   e) Transparência na comunicação das limitações do modelo

5. PRÓXIMOS PASSOS:
   • Expandir análise para outros grupos protegidos
   • Testar técnicas de pré-processamento (reweighting)
   • Implementar sistema de feedback para correção de erros
   • Desenvolver dashboard de monitoramento em tempo real
""")

print("\n" + "=" * 80)
print("ANÁLISE CONCLUÍDA COM SUCESSO!")
print("=" * 80)
print("\nArquivos gerados:")
print("  • dropout_fairness_analysis.py - Script Python executável")
print("  • images/target_distribution.png - Distribuição do target")
print("  • images/confusion_matrix.png - Matriz de confusão")
print("  • images/metrics_by_scholarship.png - Métricas por bolsa")
print("  • images/disparity_comparison.png - Comparação de disparidades")
print("\nRelatório técnico disponível em: technical_report.tex")